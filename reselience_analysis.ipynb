{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d61ea77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from util.reselience_metrics import (\n",
    "    EvalWindows,\n",
    "    to_performance,\n",
    "    compute_all,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d7bd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === PATH TO YOUR RUN FILES (.npz) ===\n",
    "PATH_PERT = \"\"     # run WITH perturbation\n",
    "PATH_BASE = \"\"              # control run WITHOUT perturbation\n",
    "\n",
    "# time axis (must exist in BOTH files)\n",
    "TIME_KEY = \"t\"\n",
    "\n",
    "# Metric keys (one pair per performance metric you want to evaluate)\n",
    "KEYMAP = {\n",
    "    \"speed\":  (\"avg_speed\", \"avg_speed\"),        # (pert_key, base_key)\n",
    "    \"queue\":  (\"total_queue\", \"total_queue\"),\n",
    "    \"wait\":   (\"total_wait\", \"total_wait\"),\n",
    "    \"ret\": (\"avg_reward\", \"avg_reward\"),\n",
    "}\n",
    "\n",
    "# Which metrics to evaluate in this run\n",
    "SELECTED = [\"speed\", \"queue\", \"wait\"]  # or [\"speed\"] or add \"reward\" if meaningful\n",
    "\n",
    "# === Windows (seconds or steps; must match your time units) ===\n",
    "wins = EvalWindows(\n",
    "    pre_start=0,  # start of pre-shock window\n",
    "    t0=600,         # shock start\n",
    "    t1=1800,         # shock end\n",
    "    post_end=3600    # end of evaluation horizon\n",
    ")\n",
    "\n",
    "# Normalization rule baked in our util:\n",
    "# - higher_is_better=True  -> minmax\n",
    "# - higher_is_better=False -> inv1p\n",
    "DIRECTION = {\n",
    "    \"speed\":  True,   # higher is better\n",
    "    \"reward\": True,   # often higher is better (if your reward is aligned that way)\n",
    "    \"queue\":  False,  # lower is better\n",
    "    \"wait\":   False,  # lower is better\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3df3192",
   "metadata": {},
   "outputs": [],
   "source": [
    "def array_to_series(t: np.ndarray, x: np.ndarray) -> pd.Series:\n",
    "    \"\"\"Create a pandas Series indexed by time/step.\"\"\"\n",
    "    if x.shape != t.shape:\n",
    "        raise ValueError(f\"Shape mismatch: t{t.shape} vs x{x.shape}\")\n",
    "    return pd.Series(x.astype(float), index=t.astype(float)).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aae6fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load files\n",
    "pert = np.load(PATH_PERT)\n",
    "base = np.load(PATH_BASE)\n",
    "\n",
    "# Extract time axes\n",
    "t_pert = pert[TIME_KEY]\n",
    "t_base = base[TIME_KEY]\n",
    "\n",
    "# For convenience, build a dict of series per metric\n",
    "series_pert = {}\n",
    "series_base = {}\n",
    "\n",
    "for name in SELECTED:\n",
    "    k_pert, k_base = KEYMAP[name]\n",
    "    x_pert = pert[k_pert]\n",
    "    x_base = base[k_base]\n",
    "    series_pert[name] = array_to_series(t_pert, x_pert)\n",
    "    series_base[name] = array_to_series(t_base, x_base)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c4fc3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "for name in SELECTED:\n",
    "    higher_is_better = DIRECTION[name]\n",
    "\n",
    "    # 1) Normalize perturbed run into performance P(t)\n",
    "    P = to_performance(\n",
    "        series_pert[name],\n",
    "        higher_is_better=higher_is_better,\n",
    "        ref_window=wins.pre,   # normalize on pre window for comparability\n",
    "        allow_clip=False       # keep excursions beyond [0,1]\n",
    "    )\n",
    "\n",
    "    # 2) Compute resilience metrics using baseline raw series\n",
    "    res = compute_all(\n",
    "        P, wins,\n",
    "        baseline_raw=series_base[name],\n",
    "        higher_is_better=higher_is_better,\n",
    "        target=0.90,           # RT90\n",
    "        band=0.05              # Â±5% settling band\n",
    "    )\n",
    "    res[\"metric\"] = name\n",
    "    rows.append(res)\n",
    "\n",
    "res_df = pd.DataFrame(rows).set_index(\"metric\")\n",
    "res_df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
